{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 About Log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** When we dealing with regression problem, It's an important idea to test wether the *numerical* features are skew features or not. If the skewness is large(>0.75 maybe), Using log-trasformation is a good idea.Most of the machine learning algorithms work better if the features have a normal distribution.**\n",
    "[more details](https://stats.stackexchange.com/questions/18844/when-and-why-should-you-take-the-log-of-a-distribution-of-numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 How to find outliers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Which set are you operating on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** When we are dong Data processing/Feature Engineering, Notice witch set we are operating on : train_df, test_df, all_data...**  \n",
    "** Target Feature is usually just in train_df rather than test_df or total_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 When draw some stastic plots, if the plot look skewed, try to find underlying outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 sns plot may not include 'None' value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** If you want to convert the feature into numerical type, Do not forget 'None' **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6 Normal Features processing method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Categorical type:  \n",
    " 1. Has significant relationship with Target variable:\n",
    "    1. Have some unique categories : Convert to concessive integer type. \n",
    "    2. Have only few unique categories : \n",
    " 2. Doesn't have close relationship with target variable:  \n",
    "    Create dummy variables for the feature.  \n",
    "    ** Note: When Feature is discrete numerical type, treat it as categorical type. **\n",
    "2. Numerical type:  \n",
    " 1. Has big correlation with Target variable:  \n",
    " Divide the feature into discrete bins, (Then Dummy it)?\n",
    " 2. Has small correlation with Target variable:  \n",
    " See the concrete situation: If most values are 0(or some number else), create Falg feature(bool type)  \n",
    " Or just Delete the feature.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Noticing: Many situation is flexible, such if some category value count is very low, you can merge it into other category.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
